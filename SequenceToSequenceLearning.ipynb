{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzoWRWbb/oZxjgf7cwzugx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/necronet/Notebooks/blob/master/SequenceToSequenceLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_OaakpQcDf",
        "colab_type": "text"
      },
      "source": [
        "# Sequence to sequence learning for performing number addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JIGwKqVQejq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg8UiHw0QsWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84c9c9fd-a0b6-4f20-872c-0aab101144f1"
      },
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I03tKljwW0Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "231c960b-ee08-4d0b-8c57-093c6c491618"
      },
      "source": [
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDPazmpXAIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "80a59eae-f8c4-4140-f2ea-4749474afdab"
      },
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFwwzctGXFzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8dfcf939-64d5-43c8-c704-dadb3b52236c"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7698 - accuracy: 0.3531 - val_loss: 1.6021 - val_accuracy: 0.3986\n",
            "Q 67+349  T 416  ☒ 428 \n",
            "Q 88+367  T 455  ☒ 828 \n",
            "Q 14+23   T 37   ☒ 12  \n",
            "Q 38+292  T 330  ☒ 228 \n",
            "Q 438+125 T 563  ☒ 688 \n",
            "Q 318+879 T 1197 ☒ 1278\n",
            "Q 10+858  T 868  ☒ 222 \n",
            "Q 280+165 T 445  ☒ 688 \n",
            "Q 742+6   T 748  ☒ 728 \n",
            "Q 310+44  T 354  ☒ 448 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3504 - accuracy: 0.4956 - val_loss: 1.1727 - val_accuracy: 0.5594\n",
            "Q 866+917 T 1783 ☒ 1713\n",
            "Q 67+875  T 942  ☒ 979 \n",
            "Q 129+55  T 184  ☒ 183 \n",
            "Q 863+91  T 954  ☒ 966 \n",
            "Q 539+598 T 1137 ☒ 1113\n",
            "Q 5+325   T 330  ☒ 338 \n",
            "Q 805+52  T 857  ☒ 885 \n",
            "Q 88+941  T 1029 ☒ 1030\n",
            "Q 30+791  T 821  ☒ 839 \n",
            "Q 202+25  T 227  ☒ 231 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0526 - accuracy: 0.6089 - val_loss: 0.9590 - val_accuracy: 0.6458\n",
            "Q 40+573  T 613  ☒ 619 \n",
            "Q 697+77  T 774  ☒ 764 \n",
            "Q 55+357  T 412  ☒ 413 \n",
            "Q 183+52  T 235  ☒ 232 \n",
            "Q 674+41  T 715  ☒ 725 \n",
            "Q 284+12  T 296  ☒ 299 \n",
            "Q 649+52  T 701  ☒ 707 \n",
            "Q 7+11    T 18   ☒ 20  \n",
            "Q 707+99  T 806  ☒ 807 \n",
            "Q 682+973 T 1655 ☒ 1639\n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8787 - accuracy: 0.6754 - val_loss: 0.8441 - val_accuracy: 0.6824\n",
            "Q 93+497  T 590  ☒ 588 \n",
            "Q 23+255  T 278  ☒ 274 \n",
            "Q 579+857 T 1436 ☒ 1434\n",
            "Q 950+618 T 1568 ☒ 1565\n",
            "Q 60+486  T 546  ☒ 536 \n",
            "Q 976+653 T 1629 ☒ 1613\n",
            "Q 54+522  T 576  ☒ 564 \n",
            "Q 419+3   T 422  ☒ 426 \n",
            "Q 700+235 T 935  ☒ 934 \n",
            "Q 184+469 T 653  ☒ 654 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.7848 - accuracy: 0.7128 - val_loss: 0.7605 - val_accuracy: 0.7199\n",
            "Q 722+89  T 811  ☒ 817 \n",
            "Q 11+706  T 717  ☒ 728 \n",
            "Q 697+608 T 1305 ☒ 1307\n",
            "Q 924+99  T 1023 ☒ 1021\n",
            "Q 417+57  T 474  ☒ 476 \n",
            "Q 4+505   T 509  ☒ 518 \n",
            "Q 82+362  T 444  ☒ 449 \n",
            "Q 606+48  T 654  ☒ 659 \n",
            "Q 40+84   T 124  ☑ 124 \n",
            "Q 65+475  T 540  ☒ 549 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7196 - accuracy: 0.7387 - val_loss: 0.6896 - val_accuracy: 0.7523\n",
            "Q 0+757   T 757  ☒ 759 \n",
            "Q 6+259   T 265  ☒ 264 \n",
            "Q 742+803 T 1545 ☒ 1549\n",
            "Q 6+276   T 282  ☒ 280 \n",
            "Q 469+67  T 536  ☒ 532 \n",
            "Q 364+21  T 385  ☒ 384 \n",
            "Q 3+321   T 324  ☒ 327 \n",
            "Q 663+50  T 713  ☒ 710 \n",
            "Q 29+833  T 862  ☒ 865 \n",
            "Q 8+177   T 185  ☑ 185 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6159 - accuracy: 0.7762 - val_loss: 0.4897 - val_accuracy: 0.8253\n",
            "Q 915+18  T 933  ☑ 933 \n",
            "Q 91+71   T 162  ☒ 163 \n",
            "Q 19+6    T 25   ☑ 25  \n",
            "Q 892+2   T 894  ☑ 894 \n",
            "Q 39+893  T 932  ☒ 931 \n",
            "Q 790+494 T 1284 ☒ 1171\n",
            "Q 30+564  T 594  ☒ 595 \n",
            "Q 690+29  T 719  ☒ 718 \n",
            "Q 52+14   T 66   ☒ 67  \n",
            "Q 16+950  T 966  ☒ 965 \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.3459 - accuracy: 0.8875 - val_loss: 0.2916 - val_accuracy: 0.9074\n",
            "Q 965+360 T 1325 ☑ 1325\n",
            "Q 52+6    T 58   ☑ 58  \n",
            "Q 108+73  T 181  ☑ 181 \n",
            "Q 78+728  T 806  ☒ 896 \n",
            "Q 89+342  T 431  ☑ 431 \n",
            "Q 680+233 T 913  ☑ 913 \n",
            "Q 578+4   T 582  ☑ 582 \n",
            "Q 13+324  T 337  ☑ 337 \n",
            "Q 491+227 T 718  ☑ 718 \n",
            "Q 69+124  T 193  ☑ 193 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.1888 - accuracy: 0.9514 - val_loss: 0.1367 - val_accuracy: 0.9684\n",
            "Q 7+151   T 158  ☑ 158 \n",
            "Q 396+949 T 1345 ☑ 1345\n",
            "Q 250+133 T 383  ☑ 383 \n",
            "Q 92+442  T 534  ☑ 534 \n",
            "Q 369+621 T 990  ☑ 990 \n",
            "Q 873+502 T 1375 ☑ 1375\n",
            "Q 536+57  T 593  ☑ 593 \n",
            "Q 38+51   T 89   ☑ 89  \n",
            "Q 588+55  T 643  ☑ 643 \n",
            "Q 91+216  T 307  ☑ 307 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.1138 - accuracy: 0.9733 - val_loss: 0.0782 - val_accuracy: 0.9839\n",
            "Q 39+55   T 94   ☑ 94  \n",
            "Q 685+174 T 859  ☑ 859 \n",
            "Q 829+703 T 1532 ☑ 1532\n",
            "Q 252+21  T 273  ☑ 273 \n",
            "Q 350+435 T 785  ☑ 785 \n",
            "Q 155+19  T 174  ☑ 174 \n",
            "Q 863+75  T 938  ☑ 938 \n",
            "Q 924+769 T 1693 ☑ 1693\n",
            "Q 73+49   T 122  ☑ 122 \n",
            "Q 14+552  T 566  ☑ 566 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0764 - accuracy: 0.9823 - val_loss: 0.1063 - val_accuracy: 0.9712\n",
            "Q 501+18  T 519  ☑ 519 \n",
            "Q 113+42  T 155  ☑ 155 \n",
            "Q 89+125  T 214  ☑ 214 \n",
            "Q 25+560  T 585  ☑ 585 \n",
            "Q 879+793 T 1672 ☒ 1682\n",
            "Q 915+18  T 933  ☑ 933 \n",
            "Q 875+31  T 906  ☑ 906 \n",
            "Q 208+751 T 959  ☑ 959 \n",
            "Q 636+917 T 1553 ☑ 1553\n",
            "Q 212+203 T 415  ☑ 415 \n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0598 - accuracy: 0.9850 - val_loss: 0.0441 - val_accuracy: 0.9889\n",
            "Q 89+603  T 692  ☑ 692 \n",
            "Q 994+921 T 1915 ☒ 1914\n",
            "Q 10+952  T 962  ☑ 962 \n",
            "Q 202+16  T 218  ☑ 218 \n",
            "Q 927+9   T 936  ☑ 936 \n",
            "Q 4+629   T 633  ☑ 633 \n",
            "Q 675+44  T 719  ☑ 719 \n",
            "Q 884+878 T 1762 ☑ 1762\n",
            "Q 84+877  T 961  ☑ 961 \n",
            "Q 8+477   T 485  ☑ 485 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0486 - accuracy: 0.9879 - val_loss: 0.1777 - val_accuracy: 0.9475\n",
            "Q 231+796 T 1027 ☒ 1127\n",
            "Q 755+498 T 1253 ☑ 1253\n",
            "Q 271+737 T 1008 ☒ 1108\n",
            "Q 4+236   T 240  ☑ 240 \n",
            "Q 259+991 T 1250 ☒ 1350\n",
            "Q 92+184  T 276  ☑ 276 \n",
            "Q 691+8   T 699  ☑ 699 \n",
            "Q 150+112 T 262  ☑ 262 \n",
            "Q 12+510  T 522  ☑ 522 \n",
            "Q 92+657  T 749  ☑ 749 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0438 - accuracy: 0.9880 - val_loss: 0.0724 - val_accuracy: 0.9764\n",
            "Q 26+444  T 470  ☑ 470 \n",
            "Q 215+11  T 226  ☑ 226 \n",
            "Q 72+242  T 314  ☑ 314 \n",
            "Q 91+216  T 307  ☑ 307 \n",
            "Q 969+81  T 1050 ☑ 1050\n",
            "Q 533+334 T 867  ☑ 867 \n",
            "Q 9+594   T 603  ☒ 602 \n",
            "Q 854+632 T 1486 ☑ 1486\n",
            "Q 404+733 T 1137 ☑ 1137\n",
            "Q 14+102  T 116  ☑ 116 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0662 - val_accuracy: 0.9779\n",
            "Q 736+1   T 737  ☑ 737 \n",
            "Q 72+969  T 1041 ☒ 1051\n",
            "Q 1+325   T 326  ☒ 327 \n",
            "Q 558+950 T 1508 ☒ 1408\n",
            "Q 54+522  T 576  ☑ 576 \n",
            "Q 567+353 T 920  ☑ 920 \n",
            "Q 2+750   T 752  ☑ 752 \n",
            "Q 97+462  T 559  ☑ 559 \n",
            "Q 912+60  T 972  ☑ 972 \n",
            "Q 773+264 T 1037 ☑ 1037\n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0448 - val_accuracy: 0.9880\n",
            "Q 743+715 T 1458 ☑ 1458\n",
            "Q 751+35  T 786  ☑ 786 \n",
            "Q 869+65  T 934  ☑ 934 \n",
            "Q 91+207  T 298  ☑ 298 \n",
            "Q 241+767 T 1008 ☒ 909 \n",
            "Q 566+995 T 1561 ☒ 1461\n",
            "Q 868+224 T 1092 ☑ 1092\n",
            "Q 59+381  T 440  ☑ 440 \n",
            "Q 22+638  T 660  ☑ 660 \n",
            "Q 87+734  T 821  ☑ 821 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0161 - val_accuracy: 0.9964\n",
            "Q 53+590  T 643  ☑ 643 \n",
            "Q 427+8   T 435  ☑ 435 \n",
            "Q 775+774 T 1549 ☑ 1549\n",
            "Q 13+703  T 716  ☑ 716 \n",
            "Q 2+268   T 270  ☑ 270 \n",
            "Q 54+522  T 576  ☑ 576 \n",
            "Q 981+764 T 1745 ☑ 1745\n",
            "Q 933+463 T 1396 ☑ 1396\n",
            "Q 934+2   T 936  ☑ 936 \n",
            "Q 42+867  T 909  ☑ 909 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0207 - val_accuracy: 0.9948\n",
            "Q 90+374  T 464  ☑ 464 \n",
            "Q 370+40  T 410  ☑ 410 \n",
            "Q 80+2    T 82   ☑ 82  \n",
            "Q 60+196  T 256  ☑ 256 \n",
            "Q 811+883 T 1694 ☑ 1694\n",
            "Q 244+932 T 1176 ☑ 1176\n",
            "Q 700+0   T 700  ☑ 700 \n",
            "Q 837+781 T 1618 ☑ 1618\n",
            "Q 30+856  T 886  ☑ 886 \n",
            "Q 89+389  T 478  ☑ 478 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0300 - accuracy: 0.9916 - val_loss: 0.0124 - val_accuracy: 0.9972\n",
            "Q 891+824 T 1715 ☑ 1715\n",
            "Q 1+885   T 886  ☑ 886 \n",
            "Q 61+624  T 685  ☑ 685 \n",
            "Q 441+75  T 516  ☑ 516 \n",
            "Q 6+225   T 231  ☑ 231 \n",
            "Q 738+655 T 1393 ☑ 1393\n",
            "Q 976+653 T 1629 ☑ 1629\n",
            "Q 442+0   T 442  ☑ 442 \n",
            "Q 483+59  T 542  ☑ 542 \n",
            "Q 879+330 T 1209 ☑ 1209\n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0234 - val_accuracy: 0.9927\n",
            "Q 851+830 T 1681 ☑ 1681\n",
            "Q 772+284 T 1056 ☑ 1056\n",
            "Q 75+75   T 150  ☑ 150 \n",
            "Q 885+786 T 1671 ☑ 1671\n",
            "Q 64+1    T 65   ☑ 65  \n",
            "Q 491+817 T 1308 ☑ 1308\n",
            "Q 16+373  T 389  ☑ 389 \n",
            "Q 416+10  T 426  ☑ 426 \n",
            "Q 43+499  T 542  ☑ 542 \n",
            "Q 546+65  T 611  ☑ 611 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
            "Q 4+266   T 270  ☑ 270 \n",
            "Q 850+49  T 899  ☑ 899 \n",
            "Q 717+7   T 724  ☑ 724 \n",
            "Q 400+26  T 426  ☑ 426 \n",
            "Q 3+214   T 217  ☑ 217 \n",
            "Q 988+829 T 1817 ☑ 1817\n",
            "Q 964+52  T 1016 ☑ 1016\n",
            "Q 29+25   T 54   ☑ 54  \n",
            "Q 668+5   T 673  ☑ 673 \n",
            "Q 230+29  T 259  ☑ 259 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9804\n",
            "Q 595+11  T 606  ☑ 606 \n",
            "Q 273+428 T 701  ☑ 701 \n",
            "Q 892+68  T 960  ☑ 960 \n",
            "Q 229+562 T 791  ☑ 791 \n",
            "Q 957+1   T 958  ☑ 958 \n",
            "Q 7+716   T 723  ☑ 723 \n",
            "Q 371+375 T 746  ☑ 746 \n",
            "Q 25+635  T 660  ☑ 660 \n",
            "Q 60+30   T 90   ☑ 90  \n",
            "Q 4+250   T 254  ☑ 254 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0300 - val_accuracy: 0.9906\n",
            "Q 864+459 T 1323 ☑ 1323\n",
            "Q 189+756 T 945  ☑ 945 \n",
            "Q 385+645 T 1030 ☑ 1030\n",
            "Q 16+373  T 389  ☑ 389 \n",
            "Q 74+677  T 751  ☑ 751 \n",
            "Q 21+30   T 51   ☑ 51  \n",
            "Q 21+685  T 706  ☑ 706 \n",
            "Q 73+86   T 159  ☑ 159 \n",
            "Q 22+62   T 84   ☑ 84  \n",
            "Q 137+2   T 139  ☑ 139 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
            "Q 118+72  T 190  ☑ 190 \n",
            "Q 32+208  T 240  ☑ 240 \n",
            "Q 53+356  T 409  ☑ 409 \n",
            "Q 15+307  T 322  ☑ 322 \n",
            "Q 45+9    T 54   ☑ 54  \n",
            "Q 754+0   T 754  ☑ 754 \n",
            "Q 66+606  T 672  ☑ 672 \n",
            "Q 43+608  T 651  ☑ 651 \n",
            "Q 8+116   T 124  ☑ 124 \n",
            "Q 710+18  T 728  ☑ 728 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 0.0080 - val_accuracy: 0.9985\n",
            "Q 347+931 T 1278 ☑ 1278\n",
            "Q 90+833  T 923  ☑ 923 \n",
            "Q 43+623  T 666  ☑ 666 \n",
            "Q 142+70  T 212  ☑ 212 \n",
            "Q 717+99  T 816  ☑ 816 \n",
            "Q 765+99  T 864  ☑ 864 \n",
            "Q 23+96   T 119  ☑ 119 \n",
            "Q 435+0   T 435  ☑ 435 \n",
            "Q 774+49  T 823  ☑ 823 \n",
            "Q 70+689  T 759  ☑ 759 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.1426 - val_accuracy: 0.9551\n",
            "Q 602+693 T 1295 ☑ 1295\n",
            "Q 97+462  T 559  ☑ 559 \n",
            "Q 6+60    T 66   ☑ 66  \n",
            "Q 0+272   T 272  ☑ 272 \n",
            "Q 96+666  T 762  ☑ 762 \n",
            "Q 411+41  T 452  ☑ 452 \n",
            "Q 754+37  T 791  ☑ 791 \n",
            "Q 167+88  T 255  ☑ 255 \n",
            "Q 333+3   T 336  ☒ 337 \n",
            "Q 77+88   T 165  ☑ 165 \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
            "Q 14+401  T 415  ☑ 415 \n",
            "Q 567+353 T 920  ☑ 920 \n",
            "Q 570+790 T 1360 ☑ 1360\n",
            "Q 171+1   T 172  ☑ 172 \n",
            "Q 131+55  T 186  ☑ 186 \n",
            "Q 86+549  T 635  ☑ 635 \n",
            "Q 7+13    T 20   ☑ 20  \n",
            "Q 97+80   T 177  ☑ 177 \n",
            "Q 763+962 T 1725 ☑ 1725\n",
            "Q 325+385 T 710  ☑ 710 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Q 11+432  T 443  ☑ 443 \n",
            "Q 431+7   T 438  ☑ 438 \n",
            "Q 64+118  T 182  ☑ 182 \n",
            "Q 386+95  T 481  ☑ 481 \n",
            "Q 423+801 T 1224 ☑ 1224\n",
            "Q 125+801 T 926  ☑ 926 \n",
            "Q 89+568  T 657  ☑ 657 \n",
            "Q 541+109 T 650  ☑ 650 \n",
            "Q 6+883   T 889  ☑ 889 \n",
            "Q 4+100   T 104  ☑ 104 \n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0410 - val_accuracy: 0.9862\n",
            "Q 932+32  T 964  ☑ 964 \n",
            "Q 2+232   T 234  ☑ 234 \n",
            "Q 438+3   T 441  ☑ 441 \n",
            "Q 1+803   T 804  ☑ 804 \n",
            "Q 968+585 T 1553 ☑ 1553\n",
            "Q 600+48  T 648  ☑ 648 \n",
            "Q 704+11  T 715  ☑ 715 \n",
            "Q 84+21   T 105  ☑ 105 \n",
            "Q 553+554 T 1107 ☑ 1107\n",
            "Q 58+26   T 84   ☑ 84  \n",
            "\n",
            "Iteration 30\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
            "Q 360+26  T 386  ☑ 386 \n",
            "Q 40+81   T 121  ☑ 121 \n",
            "Q 979+793 T 1772 ☑ 1772\n",
            "Q 527+681 T 1208 ☑ 1208\n",
            "Q 184+549 T 733  ☑ 733 \n",
            "Q 513+86  T 599  ☑ 599 \n",
            "Q 83+76   T 159  ☑ 159 \n",
            "Q 67+349  T 416  ☑ 416 \n",
            "Q 416+512 T 928  ☑ 928 \n",
            "Q 136+11  T 147  ☑ 147 \n",
            "\n",
            "Iteration 31\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
            "Q 583+46  T 629  ☑ 629 \n",
            "Q 239+32  T 271  ☑ 271 \n",
            "Q 487+8   T 495  ☑ 495 \n",
            "Q 62+603  T 665  ☑ 665 \n",
            "Q 0+448   T 448  ☑ 448 \n",
            "Q 9+973   T 982  ☑ 982 \n",
            "Q 841+8   T 849  ☑ 849 \n",
            "Q 572+2   T 574  ☑ 574 \n",
            "Q 116+2   T 118  ☑ 118 \n",
            "Q 84+112  T 196  ☑ 196 \n",
            "\n",
            "Iteration 32\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Q 288+694 T 982  ☑ 982 \n",
            "Q 956+46  T 1002 ☑ 1002\n",
            "Q 160+733 T 893  ☑ 893 \n",
            "Q 56+35   T 91   ☑ 91  \n",
            "Q 173+847 T 1020 ☑ 1020\n",
            "Q 71+71   T 142  ☑ 142 \n",
            "Q 254+35  T 289  ☑ 289 \n",
            "Q 198+254 T 452  ☑ 452 \n",
            "Q 138+985 T 1123 ☑ 1123\n",
            "Q 64+190  T 254  ☑ 254 \n",
            "\n",
            "Iteration 33\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0234 - accuracy: 0.9935 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
            "Q 9+616   T 625  ☑ 625 \n",
            "Q 727+626 T 1353 ☑ 1353\n",
            "Q 232+32  T 264  ☑ 264 \n",
            "Q 244+0   T 244  ☑ 244 \n",
            "Q 395+215 T 610  ☑ 610 \n",
            "Q 816+12  T 828  ☑ 828 \n",
            "Q 734+9   T 743  ☑ 743 \n",
            "Q 9+808   T 817  ☑ 817 \n",
            "Q 96+450  T 546  ☑ 546 \n",
            "Q 893+59  T 952  ☑ 952 \n",
            "\n",
            "Iteration 34\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0176 - val_accuracy: 0.9948\n",
            "Q 861+250 T 1111 ☑ 1111\n",
            "Q 517+4   T 521  ☑ 521 \n",
            "Q 993+41  T 1034 ☑ 1034\n",
            "Q 229+977 T 1206 ☑ 1206\n",
            "Q 61+586  T 647  ☑ 647 \n",
            "Q 45+94   T 139  ☑ 139 \n",
            "Q 459+831 T 1290 ☑ 1290\n",
            "Q 373+9   T 382  ☑ 382 \n",
            "Q 134+716 T 850  ☑ 850 \n",
            "Q 29+974  T 1003 ☑ 1003\n",
            "\n",
            "Iteration 35\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1188 - val_accuracy: 0.9647\n",
            "Q 64+785  T 849  ☑ 849 \n",
            "Q 59+840  T 899  ☑ 899 \n",
            "Q 467+302 T 769  ☒ 759 \n",
            "Q 299+846 T 1145 ☑ 1145\n",
            "Q 495+95  T 590  ☑ 590 \n",
            "Q 578+4   T 582  ☑ 582 \n",
            "Q 706+677 T 1383 ☑ 1383\n",
            "Q 26+36   T 62   ☑ 62  \n",
            "Q 823+245 T 1068 ☑ 1068\n",
            "Q 136+11  T 147  ☑ 147 \n",
            "\n",
            "Iteration 36\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0300 - val_accuracy: 0.9908\n",
            "Q 93+636  T 729  ☑ 729 \n",
            "Q 543+7   T 550  ☑ 550 \n",
            "Q 986+762 T 1748 ☑ 1748\n",
            "Q 38+657  T 695  ☑ 695 \n",
            "Q 357+5   T 362  ☑ 362 \n",
            "Q 593+941 T 1534 ☑ 1534\n",
            "Q 674+5   T 679  ☑ 679 \n",
            "Q 211+316 T 527  ☒ 526 \n",
            "Q 571+8   T 579  ☑ 579 \n",
            "Q 46+366  T 412  ☑ 412 \n",
            "\n",
            "Iteration 37\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
            "Q 727+46  T 773  ☑ 773 \n",
            "Q 441+398 T 839  ☑ 839 \n",
            "Q 627+7   T 634  ☑ 634 \n",
            "Q 24+82   T 106  ☑ 106 \n",
            "Q 46+205  T 251  ☑ 251 \n",
            "Q 824+198 T 1022 ☑ 1022\n",
            "Q 0+577   T 577  ☑ 577 \n",
            "Q 616+884 T 1500 ☑ 1500\n",
            "Q 129+486 T 615  ☑ 615 \n",
            "Q 533+710 T 1243 ☑ 1243\n",
            "\n",
            "Iteration 38\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
            "Q 70+5    T 75   ☑ 75  \n",
            "Q 645+34  T 679  ☑ 679 \n",
            "Q 606+395 T 1001 ☑ 1001\n",
            "Q 892+172 T 1064 ☑ 1064\n",
            "Q 271+737 T 1008 ☑ 1008\n",
            "Q 670+2   T 672  ☑ 672 \n",
            "Q 58+635  T 693  ☑ 693 \n",
            "Q 353+97  T 450  ☑ 450 \n",
            "Q 386+89  T 475  ☑ 475 \n",
            "Q 78+439  T 517  ☑ 517 \n",
            "\n",
            "Iteration 39\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
            "Q 55+595  T 650  ☑ 650 \n",
            "Q 26+444  T 470  ☑ 470 \n",
            "Q 978+562 T 1540 ☑ 1540\n",
            "Q 1+803   T 804  ☑ 804 \n",
            "Q 368+104 T 472  ☑ 472 \n",
            "Q 964+25  T 989  ☑ 989 \n",
            "Q 795+34  T 829  ☑ 829 \n",
            "Q 581+4   T 585  ☑ 585 \n",
            "Q 223+20  T 243  ☑ 243 \n",
            "Q 85+60   T 145  ☑ 145 \n",
            "\n",
            "Iteration 40\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0169 - val_accuracy: 0.9942\n",
            "Q 683+62  T 745  ☑ 745 \n",
            "Q 12+100  T 112  ☑ 112 \n",
            "Q 435+0   T 435  ☑ 435 \n",
            "Q 765+3   T 768  ☑ 768 \n",
            "Q 15+307  T 322  ☑ 322 \n",
            "Q 51+835  T 886  ☑ 886 \n",
            "Q 201+9   T 210  ☑ 210 \n",
            "Q 887+5   T 892  ☑ 892 \n",
            "Q 560+576 T 1136 ☑ 1136\n",
            "Q 516+27  T 543  ☑ 543 \n",
            "\n",
            "Iteration 41\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Q 958+22  T 980  ☑ 980 \n",
            "Q 655+7   T 662  ☑ 662 \n",
            "Q 913+43  T 956  ☑ 956 \n",
            "Q 4+510   T 514  ☑ 514 \n",
            "Q 594+77  T 671  ☑ 671 \n",
            "Q 895+714 T 1609 ☑ 1609\n",
            "Q 618+91  T 709  ☑ 709 \n",
            "Q 82+354  T 436  ☑ 436 \n",
            "Q 601+2   T 603  ☑ 603 \n",
            "Q 43+608  T 651  ☑ 651 \n",
            "\n",
            "Iteration 42\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
            "Q 972+639 T 1611 ☑ 1611\n",
            "Q 98+3    T 101  ☑ 101 \n",
            "Q 205+72  T 277  ☑ 277 \n",
            "Q 56+853  T 909  ☑ 909 \n",
            "Q 83+746  T 829  ☑ 829 \n",
            "Q 444+88  T 532  ☑ 532 \n",
            "Q 531+45  T 576  ☑ 576 \n",
            "Q 122+702 T 824  ☑ 824 \n",
            "Q 708+655 T 1363 ☑ 1363\n",
            "Q 31+682  T 713  ☑ 713 \n",
            "\n",
            "Iteration 43\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0377 - val_accuracy: 0.9894\n",
            "Q 75+904  T 979  ☑ 979 \n",
            "Q 718+82  T 800  ☑ 800 \n",
            "Q 84+90   T 174  ☑ 174 \n",
            "Q 565+1   T 566  ☑ 566 \n",
            "Q 26+643  T 669  ☑ 669 \n",
            "Q 173+88  T 261  ☑ 261 \n",
            "Q 84+537  T 621  ☑ 621 \n",
            "Q 697+77  T 774  ☑ 774 \n",
            "Q 46+474  T 520  ☑ 520 \n",
            "Q 314+2   T 316  ☑ 316 \n",
            "\n",
            "Iteration 44\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
            "Q 99+601  T 700  ☑ 700 \n",
            "Q 9+259   T 268  ☑ 268 \n",
            "Q 22+744  T 766  ☑ 766 \n",
            "Q 504+8   T 512  ☑ 512 \n",
            "Q 225+3   T 228  ☑ 228 \n",
            "Q 245+5   T 250  ☑ 250 \n",
            "Q 9+713   T 722  ☑ 722 \n",
            "Q 18+18   T 36   ☑ 36  \n",
            "Q 940+768 T 1708 ☑ 1708\n",
            "Q 842+995 T 1837 ☑ 1837\n",
            "\n",
            "Iteration 45\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Q 341+9   T 350  ☑ 350 \n",
            "Q 516+600 T 1116 ☑ 1116\n",
            "Q 387+92  T 479  ☑ 479 \n",
            "Q 55+302  T 357  ☑ 357 \n",
            "Q 833+64  T 897  ☑ 897 \n",
            "Q 902+7   T 909  ☑ 909 \n",
            "Q 895+3   T 898  ☑ 898 \n",
            "Q 251+594 T 845  ☑ 845 \n",
            "Q 543+402 T 945  ☑ 945 \n",
            "Q 6+503   T 509  ☑ 509 \n",
            "\n",
            "Iteration 46\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 9.1809e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Q 602+693 T 1295 ☑ 1295\n",
            "Q 215+97  T 312  ☑ 312 \n",
            "Q 66+93   T 159  ☑ 159 \n",
            "Q 16+719  T 735  ☑ 735 \n",
            "Q 33+114  T 147  ☑ 147 \n",
            "Q 25+255  T 280  ☑ 280 \n",
            "Q 600+48  T 648  ☑ 648 \n",
            "Q 872+61  T 933  ☑ 933 \n",
            "Q 414+366 T 780  ☑ 780 \n",
            "Q 76+990  T 1066 ☑ 1066\n",
            "\n",
            "Iteration 47\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "Q 504+696 T 1200 ☑ 1200\n",
            "Q 80+46   T 126  ☑ 126 \n",
            "Q 910+925 T 1835 ☑ 1835\n",
            "Q 87+685  T 772  ☑ 772 \n",
            "Q 76+214  T 290  ☑ 290 \n",
            "Q 507+7   T 514  ☑ 514 \n",
            "Q 477+978 T 1455 ☑ 1455\n",
            "Q 34+0    T 34   ☑ 34  \n",
            "Q 89+342  T 431  ☑ 431 \n",
            "Q 913+123 T 1036 ☑ 1036\n",
            "\n",
            "Iteration 48\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0690 - val_accuracy: 0.9768\n",
            "Q 66+769  T 835  ☑ 835 \n",
            "Q 573+72  T 645  ☑ 645 \n",
            "Q 49+103  T 152  ☒ 151 \n",
            "Q 10+57   T 67   ☑ 67  \n",
            "Q 97+80   T 177  ☑ 177 \n",
            "Q 351+758 T 1109 ☑ 1109\n",
            "Q 270+77  T 347  ☑ 347 \n",
            "Q 419+3   T 422  ☑ 422 \n",
            "Q 53+120  T 173  ☑ 173 \n",
            "Q 528+524 T 1052 ☑ 1052\n",
            "\n",
            "Iteration 49\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Q 78+42   T 120  ☑ 120 \n",
            "Q 813+241 T 1054 ☑ 1054\n",
            "Q 850+777 T 1627 ☑ 1627\n",
            "Q 62+950  T 1012 ☑ 1012\n",
            "Q 367+560 T 927  ☑ 927 \n",
            "Q 894+14  T 908  ☑ 908 \n",
            "Q 24+312  T 336  ☑ 336 \n",
            "Q 78+163  T 241  ☑ 241 \n",
            "Q 542+43  T 585  ☑ 585 \n",
            "Q 60+620  T 680  ☑ 680 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}