{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "layers and models via subclassing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8jo4nDSmj3N23IsfHQFFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/necronet/Notebooks/blob/master/layers_and_models_via_subclassing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abFgcQPpzNH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogqrFUJ0Dz3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6e48d147-2c50-4860-d7d1-d6a10f819c0f"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32, input_dim=32):\n",
        "        super(Linear, self).__init__()\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "linear_layer = Linear(4, 2)\n",
        "y = linear_layer(x)\n",
        "print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.01001536 -0.1487032  -0.01216483  0.02761656]\n",
            " [ 0.01001536 -0.1487032  -0.01216483  0.02761656]], shape=(2, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgEaRXvPvrdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert linear_layer.weights == [linear_layer.w, linear_layer.b]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiYxXmwtvsba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "735feba7-3768-4d1a-b828-570490da7e11"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32, input_dim=32):\n",
        "        super(Linear, self).__init__()\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_dim, units), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
        "  \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "linear_layer = Linear(4, 2)\n",
        "y = linear_layer(x)\n",
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.01338702  0.02389832 -0.00719325 -0.02536425]\n",
            " [-0.01338702  0.02389832 -0.00719325 -0.02536425]], shape=(2, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3svWzHfv_0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c1045c9a-e6a9-4512-8f08-116dfc548b31"
      },
      "source": [
        "class ComputeSum(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeSum, self).__init__()\n",
        "        self.total = tf.Variable(initial_value=tf.zeros((input_dim,)), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
        "        return self.total * 2\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "print(x)\n",
        "my_sum = ComputeSum(2)\n",
        "y = my_sum(x)\n",
        "print(y.numpy())\n",
        "y = my_sum(x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n",
            "[4. 4.]\n",
            "[8. 8.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfiIzAZgw6Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF9RpvfNw-sZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2912f140-a38f-485f-a20b-f18ce3cf4ca3"
      },
      "source": [
        "print(\"weights:\", len(my_sum.weights))\n",
        "print(\"non-trainable weights:\", len(my_sum.non_trainable_weights))\n",
        "\n",
        "# It's not included in the trainable weights:\n",
        "print(\"trainable_weights:\", my_sum.trainable_weights)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 1\n",
            "non-trainable weights: 1\n",
            "trainable_weights: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOqpEui9xClN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32, input_dim=32):\n",
        "        super(Linear, self).__init__()\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_dim, units), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwMZrFAwDSMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(Linear, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    # Deferring the weight creation until the input_shape is known\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q6TE2YwDxkW",
        "colab_type": "text"
      },
      "source": [
        "This should show an error since weights are yet to be calculated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmxVs2HfDYN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "9bef9837-be9e-48d6-92a9-ec5578f2d552"
      },
      "source": [
        "# At instantiation, we don't know on what inputs this is going to get called\n",
        "linear_layer = Linear(32)\n",
        "print(linear_layer.w)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e9aec43d9d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlinear_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# The layer's weights are created dynamically the first time the layer is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'w'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cwIOgyEaXQ",
        "colab_type": "text"
      },
      "source": [
        "The proper way is to provide the input for weight to be initialize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdP3OwyVEYr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80b90947-195d-4b16-957e-647f4aca9267"
      },
      "source": [
        "# The layer's weights are created dynamically the first time the layer is called\n",
        "y = linear_layer(x)\n",
        "print(linear_layer.w.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTsu25vUEgsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80f8617a-1213-4ece-c5b7-76bf3921ac60"
      },
      "source": [
        "# Let's assume we are reusing the Linear class\n",
        "# with a `build` method that we defined above.\n",
        "\n",
        "\n",
        "class MLPBlock(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.linear_1 = Linear(32)\n",
        "        self.linear_2 = Linear(32)\n",
        "        self.linear_3 = Linear(32)\n",
        "        self.linear_4 = Linear(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_3(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "mlp = MLPBlock()\n",
        "y = mlp(tf.ones(shape=(5, 64)))  # The first call to the `mlp` will create the weights\n",
        "print(\"weights len:\", len(mlp.weights))\n",
        "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
        "#print(\"weights:\", mlp.weights)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights len: 8\n",
            "trainable weights: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TupZ_3gEEj68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActivityRegularizationLayer(keras.layers.Layer):\n",
        "    def __init__(self, rate=1e-2):\n",
        "        super(ActivityRegularizationLayer, self).__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.add_loss(self.rate * tf.reduce_sum(inputs))\n",
        "        return inputs\n",
        "\n",
        "class OuterLayer(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(OuterLayer, self).__init__()\n",
        "        self.activity_reg = ActivityRegularizationLayer(1e-2)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.activity_reg(inputs)\n",
        "\n",
        "\n",
        "layer = OuterLayer()\n",
        "assert len(layer.losses) == 0  # No losses yet since the layer has never been called\n",
        "\n",
        "_ = layer(tf.zeros(1, 1))\n",
        "assert len(layer.losses) == 1  # We created one loss value\n",
        "\n",
        "# `layer.losses` gets reset at the start of each __call__\n",
        "_ = layer(tf.zeros(1, 1))\n",
        "assert len(layer.losses) == 1  # This is the loss created during the call above"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPcmlQvIB4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a97fe3ad-9edf-4e63-b1ab-c5355c04cdd6"
      },
      "source": [
        "class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(OuterLayerWithKernelRegularizer, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      print(input_shape)\n",
        "      self.dense = keras.layers.Dense(\n",
        "            input_shape[-1], kernel_regularizer=tf.keras.regularizers.l2(1e-3)\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "\n",
        "layer = OuterLayerWithKernelRegularizer()\n",
        "#_ = layer(tf.zeros((1, 1)))\n",
        "\n",
        "# This is `1e-3 * sum(layer.dense.kernel ** 2)`,\n",
        "# created by the `kernel_regularizer` above.\n",
        "print(layer.losses)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8bBm0g6IQxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train.reshape(60000, 784).astype(\"float32\") / 255, y_train)\n",
        ")\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "outputs = ActivityRegularizationLayer()(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# If there is a loss passed in `compile`, thee regularization\n",
        "# losses get added to it\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "#model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "# It's also possible not to pass any loss in `compile`,\n",
        "# since the model already has a loss to minimize, via the `add_loss`\n",
        "# call during the forward pass!\n",
        "#model.compile(optimizer=\"adam\")\n",
        "#model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Iterate over the batches of a dataset.\n",
        "for x_batch_train, y_batch_train in train_dataset:\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = layer(x_batch_train)  # Logits for this minibatch\n",
        "    # Loss value for this minibatch\n",
        "    loss_value = loss_fn(y_batch_train, logits)\n",
        "    # Add extra losses created during this forward pass:\n",
        "    loss_value += sum(model.losses)\n",
        "\n",
        "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    }
  ]
}